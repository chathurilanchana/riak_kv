
* Eunomia Multidc Version
** Abstract from the Paper

In this paper we propose a novel approach to manage the throughput vs latency tradeoff that emerges when managing updates in geo-replicated systems. Our approach consists in allowing full concurrency when processing local updates and using a deferred local serialisation procedure before shipping updates to remote datacenters. This strategy allows to implement inexpensive mechanisms to ensure system consistency requirements while avoiding intrusive effects on update operations, a major performance limitation of previous systems. We have implemented our approach as a variant of Riak KV. Our extensive evaluation shows that we outperform sequencer-based approaches by almost an order of magnitude in the maximum achievable throughput. Furthermore, unlike previous sequencer-free solutions, our approach reaches nearly optimal remote update visibility latencies without limiting throughput. 

** Requirements
   You must have [[http://erlang.org/download.html][Erlang/OTP R13B04]] or later and a GNU-style build
   system to compile and run =riak_kv=. The easiest way to utilize riak_kv is by installing the full 
   Riak application available on [[https://github.com/basho/riak][Github]].

** Start
Start each datacenter individualy in the way explained in http://docs.basho.com/riak/kv/2.2.3/using/running-a-cluster/
Then on each datacenter you need to run the below processes. Start these services on different nodes of the same dc for efficiency.
   1) riak_kv_sup: start_receiver()
   2) riak_kv_sup:start_ordering_service()
   3) riak_kv_sup: start_remote_label_receiver()
   
** Major Changes to Original riak_Kv
  Below list indicate the major changes to the riak_kv
   1) riak_kv_vnode.erl  (Modified to send labels and heartbeats to eunomia, propagate data to the remote data centers, receive data from remote datacenters and apply them when causality is satisfied)
   2) riak_kv_ordering_service.erl (This is the Eunomia service explained in the paper. Responsible for receiving heartbeats and labels from its own datacenter, stabilise them and deliver the stabilised labels to the remote datacenters once stablilsed)
   3) riak_kv_remote_os.erl (responsible for receiving stabilised labels from the remote eunomia services and notify its own dc vnodes when the remote updates are ready to be installed
   4) riak_kv_data_propergator.erl and riak_kv_receiver_perdc.erl (As the open source version of riak does not have the multidc support, we modified riak_kv to support multidc. propagator is responsible for receiving the data from reomte vnode and sending them to the responsible vnode in its own dc. For better load balancing we have one propagator per each node in dc and vnode select a random propagator from each remote dc. receiver is responslibe for receiving the remote propagator list and notifying the list of propagators to the vnodes.
   
**  Note
 I have updated the riak_kv.schema to include few more variables that I use in the code. These will be added to the etc/riak.config once you build the source. You may need to update their values according to your cluster
 
 In order to perform the experiments I used modified version of basho bench riakclient https://github.com/chathurilanchana/basho_bench/blob/causal-dev/src/basho_bench_driver_riakclient.erl. In order to use this, you will have to update https://github.com/chathurilanchana/basho_bench/blob/causal-dev/examples/riakclient.config according to your cluster
  
